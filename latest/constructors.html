<!DOCTYPE html>
<html lang="en"><head><meta charset="UTF-8"/><meta name="viewport" content="width=device-width, initial-scale=1.0"/><title>Model constructors · MixedModels</title><link href="https://cdnjs.cloudflare.com/ajax/libs/normalize/4.2.0/normalize.min.css" rel="stylesheet" type="text/css"/><link href="https://fonts.googleapis.com/css?family=Lato|Roboto+Mono" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/font-awesome/4.6.3/css/font-awesome.min.css" rel="stylesheet" type="text/css"/><link href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/9.12.0/styles/default.min.css" rel="stylesheet" type="text/css"/><script>documenterBaseURL="."</script><script src="https://cdnjs.cloudflare.com/ajax/libs/require.js/2.2.0/require.min.js" data-main="assets/documenter.js"></script><script src="siteinfo.js"></script><script src="../versions.js"></script><link href="assets/documenter.css" rel="stylesheet" type="text/css"/></head><body><nav class="toc"><a href="index.html"><img class="logo" src="assets/logo.png" alt="MixedModels logo"/></a><h1>MixedModels</h1><select id="version-selector" onChange="window.location.href=this.value" style="visibility: hidden"></select><form class="search" id="search-form" action="search.html"><input id="search-query" name="q" type="text" placeholder="Search docs"/></form><ul><li><a class="toctext" href="index.html">MixedModels.jl Documentation</a></li><li class="current"><a class="toctext" href="constructors.html">Model constructors</a><ul class="internal"><li><a class="toctext" href="#Examples-of-linear-mixed-effects-model-fits-1">Examples of linear mixed-effects model fits</a></li><li><a class="toctext" href="#Fitting-generalized-linear-mixed-models-1">Fitting generalized linear mixed models</a></li><li class="toplevel"><a class="toctext" href="#Extractor-functions-1">Extractor functions</a></li><li><a class="toctext" href="#Model-fit-statistics-1">Model-fit statistics</a></li><li><a class="toctext" href="#Fixed-effects-parameter-estimates-1">Fixed-effects parameter estimates</a></li><li><a class="toctext" href="#Covariance-parameter-estimates-1">Covariance parameter estimates</a></li><li><a class="toctext" href="#Conditional-modes-of-the-random-effects-1">Conditional modes of the random effects</a></li><li class="toplevel"><a class="toctext" href="#Optimization-of-the-objective-1">Optimization of the objective</a></li><li class="toplevel"><a class="toctext" href="#Internal-representation-1">Internal representation</a></li></ul></li><li><a class="toctext" href="optimization.html">Details of the parameter estimation</a></li><li><a class="toctext" href="bootstrap.html">Parametric bootstrap for linear mixed-effects models</a></li><li><a class="toctext" href="SimpleLMM.html">A Simple, Linear, Mixed-effects Model</a></li><li><a class="toctext" href="MultipleTerms.html">Models With Multiple Random-effects Terms</a></li><li><a class="toctext" href="nAGQ.html">Parameter estimation in GLMMs</a></li><li><a class="toctext" href="SingularCovariance.html">Singular covariance estimates in random regression models</a></li><li><a class="toctext" href="SubjectItem.html">-</a></li></ul></nav><article id="docs"><header><nav><ul><li><a href="constructors.html">Model constructors</a></li></ul><a class="edit-page" href="https://github.com/dmbates/MixedModels.jl/blob/master/docs/src/constructors.md"><span class="fa"></span> Edit on GitHub</a></nav><hr/><div id="topbar"><span>Model constructors</span><a class="fa fa-bars" href="#"></a></div></header><h1><a class="nav-anchor" id="Model-constructors-1" href="#Model-constructors-1">Model constructors</a></h1><p>The <code>lmm</code> function creates a linear mixed-effects model representation from a <code>Formula</code> and an appropriate <code>data</code> type. At present a <code>DataFrame</code> is required but that is expected to change.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.lmm" href="#MixedModels.lmm"><code>MixedModels.lmm</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">lmm(f::DataFrames.Formula, fr::DataFrames.DataFrame; weights = [], contrasts = Dict())</code></pre><p>Create a <code>LinearMixedModel</code> from <code>f</code>, a formula that contains both fixed-effects terms and random effects, and <code>fr</code>.</p><p>The return value is ready to be <code>fit!</code> but has not yet been fit.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/pls.jl#L71-L78">source</a></section><h2><a class="nav-anchor" id="Examples-of-linear-mixed-effects-model-fits-1" href="#Examples-of-linear-mixed-effects-model-fits-1">Examples of linear mixed-effects model fits</a></h2><p>For illustration, several data sets from the <em>lme4</em> package for <em>R</em> are made available in <code>.rda</code> format in this package. These include the <code>Dyestuff</code> and <code>Dyestuff2</code> data sets.</p><pre><code class="language-julia">julia&gt; using DataFrames, RData, MixedModels

julia&gt; const dat = convert(Dict{Symbol,DataFrame}, load(Pkg.dir(&quot;MixedModels&quot;, &quot;test&quot;, &quot;dat.rda&quot;)));

julia&gt; dump(dat[:Dyestuff])
DataFrames.DataFrame  30 observations of 2 variables
  G: DataArrays.PooledDataArray{String,UInt8,1}(30) Union{Nulls.Null, String}[&quot;A&quot;, &quot;A&quot;, &quot;A&quot;, &quot;A&quot;]
  Y: DataArrays.DataArray{Float64,1}(30) Union{Float64, Nulls.Null}[1545.0, 1440.0, 1440.0, 1520.0]

</code></pre><p>The columns in these data sets have been renamed for convenience. The response is always named <code>Y</code>. Potential grouping factors for random-effects terms are named <code>G</code>, <code>H</code>, etc.</p><h3><a class="nav-anchor" id="Models-with-simple,-scalar-random-effects-1" href="#Models-with-simple,-scalar-random-effects-1">Models with simple, scalar random effects</a></h3><p>The formula language in <em>Julia</em> is similar to that in <em>R</em> except that the formula must be enclosed in a call to the <code>@formula</code> macro. A basic model with simple, scalar random effects for the levels of <code>G</code> (the batch of an intermediate product, in this case) is declared and fit as</p><pre><code class="language-julia">julia&gt; fm1 = fit!(lmm(@formula(Y ~ 1 + (1|G)), dat[:Dyestuff]))
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + (1 | G)
   logLik   -2 logLik     AIC        BIC    
 -163.66353  327.32706  333.32706  337.53065

Variance components:
              Column    Variance  Std.Dev. 
 G        (Intercept)  1388.3332 37.260344
 Residual              2451.2500 49.510100
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)    1527.5   17.6946  86.326  &lt;1e-99

</code></pre><p>(If you are new to Julia you may find that this first fit takes an unexpectedly long time, due to Just-In-Time (JIT) compilation of the code. The second and subsequent calls to such functions are much faster.)</p><pre><code class="language-julia">julia&gt; @time fit!(lmm(@formula(Y ~ 1 + (1|G)), dat[:Dyestuff2]))
  0.011636 seconds (5.84 k allocations: 756.859 KiB)
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + (1 | G)
   logLik   -2 logLik     AIC        BIC    
 -81.436518 162.873037 168.873037 173.076629

Variance components:
              Column    Variance  Std.Dev. 
 G        (Intercept)   0.000000 0.0000000
 Residual              13.346099 3.6532314
 Number of obs: 30; levels of grouping factors: 6

  Fixed-effects parameters:
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)    5.6656  0.666986 8.49433  &lt;1e-16

</code></pre><h3><a class="nav-anchor" id="Simple,-scalar-random-effects-1" href="#Simple,-scalar-random-effects-1">Simple, scalar random effects</a></h3><p>A simple, scalar random effects term in a mixed-effects model formula is of the form <code>(1|G)</code>. All random effects terms end with <code>|G</code> where <code>G</code> is the <em>grouping factor</em> for the random effect. The name or, more generally, the expression <code>G</code> should evaluate to a categorical array that has a distinct set of <em>levels</em>. The random effects are associated with the levels of the grouping factor.</p><p>A <em>scalar</em> random effect is, as the name implies, one scalar value for each level of the grouping factor. A <em>simple, scalar</em> random effects term is of the form, <code>(1|G)</code>. It corresponds to a shift in the intercept for each level of the grouping factor.</p><h3><a class="nav-anchor" id="Models-with-vector-valued-random-effects-1" href="#Models-with-vector-valued-random-effects-1">Models with vector-valued random effects</a></h3><p>The <em>sleepstudy</em> data are observations of reaction time, <code>Y</code>, on several subjects, <code>G</code>, after 0 to 9 days of sleep deprivation, <code>U</code>. A model with random intercepts and random slopes for each subject, allowing for within-subject correlation of the slope and intercept, is fit as</p><pre><code class="language-julia">julia&gt; fm2 = fit!(lmm(@formula(Y ~ 1 + U + (1+U|G)), dat[:sleepstudy]))
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + U + ((1 + U) | G)
   logLik   -2 logLik     AIC        BIC    
 -875.96967 1751.93934 1763.93934 1783.09709

Variance components:
              Column    Variance  Std.Dev.   Corr.
 G        (Intercept)  565.51067 23.780468
          U             32.68212  5.716828  0.08
 Residual              654.94145 25.591824
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)   251.405   6.63226 37.9064  &lt;1e-99
U             10.4673   1.50224 6.96781  &lt;1e-11

</code></pre><p>A model with uncorrelated random effects for the intercept and slope by subject is fit as</p><pre><code class="language-julia">julia&gt; fm3 = fit!(lmm(@formula(Y ~ 1 + U + (1|G) + (0+U|G)), dat[:sleepstudy]))
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + U + (1 | G) + ((0 + U) | G)
   logLik   -2 logLik     AIC        BIC    
 -876.00163 1752.00326 1762.00326 1777.96804

Variance components:
              Column    Variance  Std.Dev.   Corr.
 G        (Intercept)  584.258974 24.17145
          U             33.632805  5.79938  0.00
 Residual              653.115782 25.55613
 Number of obs: 180; levels of grouping factors: 18

  Fixed-effects parameters:
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)   251.405   6.70771   37.48  &lt;1e-99
U             10.4673   1.51931 6.88951  &lt;1e-11

</code></pre><p>Although technically there are two random-effects <em>terms</em> in the formula for <em>fm3</em> both have the same grouping factor and, internally, are amalgamated into a single vector-valued term.</p><h3><a class="nav-anchor" id="Models-with-multiple,-scalar-random-effects-terms-1" href="#Models-with-multiple,-scalar-random-effects-terms-1">Models with multiple, scalar random-effects terms</a></h3><p>A model for the <em>Penicillin</em> data incorporates random effects for the plate, <code>G</code>, and for the sample, <code>H</code>. As every sample is used on every plate these two factors are <em>crossed</em>.</p><pre><code class="language-julia">julia&gt; fm4 = fit!(lmm(@formula(Y ~ 1 + (1|G) + (1|H)), dat[:Penicillin]))
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + (1 | G) + (1 | H)
   logLik   -2 logLik     AIC        BIC    
 -166.09417  332.18835  340.18835  352.06760

Variance components:
              Column    Variance  Std.Dev. 
 G        (Intercept)  0.7149795 0.8455646
 H        (Intercept)  3.1351924 1.7706474
 Residual              0.3024264 0.5499331
 Number of obs: 144; levels of grouping factors: 24, 6

  Fixed-effects parameters:
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)   22.9722  0.744596 30.8519  &lt;1e-99

</code></pre><p>In contrast the sample, <code>G</code>, grouping factor is <em>nested</em> within the batch, <code>H</code>, grouping factor in the <em>Pastes</em> data. That is, each level of <code>G</code> occurs in conjunction with only one level of <code>H</code>.</p><pre><code class="language-julia">julia&gt; fm5 = fit!(lmm(@formula(Y ~ 1 + (1|G) + (1|H)), dat[:Pastes]))
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + (1 | G) + (1 | H)
   logLik   -2 logLik     AIC        BIC    
 -123.99723  247.99447  255.99447  264.37184

Variance components:
              Column    Variance  Std.Dev.  
 G        (Intercept)  8.4336167 2.90406898
 H        (Intercept)  1.1991793 1.09507045
 Residual              0.6780021 0.82340884
 Number of obs: 60; levels of grouping factors: 30, 10

  Fixed-effects parameters:
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)   60.0533  0.642136 93.5212  &lt;1e-99

</code></pre><p>In observational studies it is common to encounter <em>partially crossed</em> grouping factors. For example, the <em>InstEval</em> data are course evaluations by students, <code>G</code>, of instructors, <code>H</code>. Additional covariates include the academic department, <code>I</code>, in which the course was given and <code>A</code>, whether or not it was a service course.</p><pre><code class="language-julia">julia&gt; fm6 = fit!(lmm(@formula(Y ~ 1 + A * I + (1|G) + (1|H)), dat[:InstEval]))
Linear mixed model fit by maximum likelihood
 Formula: Y ~ 1 + A * I + (1 | G) + (1 | H)
     logLik        -2 logLik          AIC             BIC       
 -1.18792777×10⁵  2.37585553×10⁵  2.37647553×10⁵  2.37932876×10⁵

Variance components:
              Column     Variance   Std.Dev.  
 G        (Intercept)  0.105417913 0.32468125
 H        (Intercept)  0.258416315 0.50834665
 Residual              1.384727796 1.17674458
 Number of obs: 73421; levels of grouping factors: 2972, 1128

  Fixed-effects parameters:
                Estimate Std.Error  z value P(&gt;|z|)
(Intercept)      3.22961  0.064053  50.4209  &lt;1e-99
A: 1            0.252025 0.0686507  3.67112  0.0002
I: 5            0.129536  0.101294  1.27882  0.2010
I: 10          -0.176751 0.0881352 -2.00545  0.0449
I: 12          0.0517102 0.0817523 0.632523  0.5270
I: 6           0.0347319  0.085621 0.405647  0.6850
I: 7             0.14594 0.0997984  1.46235  0.1436
I: 4            0.151689 0.0816897  1.85689  0.0633
I: 8            0.104206  0.118751 0.877517  0.3802
I: 9           0.0440401 0.0962985  0.45733  0.6474
I: 14          0.0517546 0.0986029 0.524879  0.5997
I: 1           0.0466719  0.101942 0.457828  0.6471
I: 3           0.0563461 0.0977925  0.57618  0.5645
I: 11          0.0596536  0.100233 0.595151  0.5517
I: 2          0.00556284  0.110867 0.050176  0.9600
A: 1 &amp; I: 5    -0.180757  0.123179 -1.46744  0.1423
A: 1 &amp; I: 10   0.0186492  0.110017 0.169512  0.8654
A: 1 &amp; I: 12   -0.282269 0.0792937  -3.5598  0.0004
A: 1 &amp; I: 6    -0.494464 0.0790278 -6.25684   &lt;1e-9
A: 1 &amp; I: 7    -0.392054  0.110313 -3.55403  0.0004
A: 1 &amp; I: 4    -0.278547 0.0823727 -3.38154  0.0007
A: 1 &amp; I: 8    -0.189526  0.111449 -1.70056  0.0890
A: 1 &amp; I: 9    -0.499868 0.0885423 -5.64553   &lt;1e-7
A: 1 &amp; I: 14   -0.497162 0.0917162 -5.42065   &lt;1e-7
A: 1 &amp; I: 1     -0.24042 0.0982071  -2.4481  0.0144
A: 1 &amp; I: 3    -0.223013 0.0890548 -2.50422  0.0123
A: 1 &amp; I: 11   -0.516997 0.0809077 -6.38997   &lt;1e-9
A: 1 &amp; I: 2    -0.384773  0.091843 -4.18946   &lt;1e-4

</code></pre><h2><a class="nav-anchor" id="Fitting-generalized-linear-mixed-models-1" href="#Fitting-generalized-linear-mixed-models-1">Fitting generalized linear mixed models</a></h2><p>To create a GLMM using</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.glmm" href="#MixedModels.glmm"><code>MixedModels.glmm</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">glmm(f::Formula, fr::ModelFrame, d::Distribution[, l::GLM.Link])</code></pre><p>Return a <code>GeneralizedLinearMixedModel</code> object.</p><p>The value is ready to be <code>fit!</code> but has not yet been fit.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/PIRLS.jl#L3-L9">source</a></section><p>the distribution family for the response, and possibly the link function, must be specified.</p><pre><code class="language-julia">julia&gt; gm1 = fit!(glmm(@formula(r2 ~ 1 + a + g + b + s + m + (1|id) + (1|item)), dat[:VerbAgg],
    Bernoulli()))
Generalized Linear Mixed Model fit by minimizing the Laplace approximation to the deviance
  Formula: r2 ~ 1 + a + g + b + s + m + (1 | id) + (1 | item)
  Distribution: Distributions.Bernoulli{Float64}
  Link: GLM.LogitLink()

  Deviance (Laplace approximation): 8135.8329

Variance components:
          Column    Variance   Std.Dev.  
 id   (Intercept)  1.79357917 1.33924575
 item (Intercept)  0.11713603 0.34225142

 Number of obs: 7584; levels of grouping factors: 316, 24

Fixed-effects parameters:
              Estimate Std.Error  z value P(&gt;|z|)
(Intercept)   0.553446  0.385367  1.43615  0.1510
a            0.0574199 0.0167532  3.42741  0.0006
g: M          0.320748  0.191212  1.67745  0.0935
b: scold       -1.0598   0.18415 -5.75508   &lt;1e-8
b: shout      -2.10382  0.186509   -11.28  &lt;1e-28
s: self       -1.05437  0.151187 -6.97393  &lt;1e-11
m: do        -0.706998     0.151  -4.6821   &lt;1e-5

</code></pre><p>The canonical link, which is <code>GLM.LogitLink</code> for the <code>Bernoulli</code> distribution, is used if no explicit link is specified.</p><p>In the <a href="https://github.com/JuliaStats/GLM.jl"><code>GLM</code> package</a> the appropriate distribution for a 0/1 response is the <code>Bernoulli</code> distribution. The <code>Binomial</code> distribution is only used when the response is the fraction of trials returning a positive, in which case the number of trials must be specified as the case weights.</p><h1><a class="nav-anchor" id="Extractor-functions-1" href="#Extractor-functions-1">Extractor functions</a></h1><p><code>LinearMixedModel</code> and <code>GeneralizedLinearMixedModel</code> are subtypes of <code>StatsBase.RegressionModel</code> which, in turn, is a subtype of <code>StatsBase.StatisticalModel</code>. Many of the generic extractors defined in the <code>StatsBase</code> package have methods for these models.</p><h2><a class="nav-anchor" id="Model-fit-statistics-1" href="#Model-fit-statistics-1">Model-fit statistics</a></h2><p>The statistics describing the quality of the model fit include</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.loglikelihood-Tuple{StatsBase.StatisticalModel}" href="#StatsBase.loglikelihood-Tuple{StatsBase.StatisticalModel}"><code>StatsBase.loglikelihood</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">loglikelihood(obj::StatisticalModel)</code></pre><p>Return the log-likelihood of the model.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L42-L46">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.aic" href="#StatsBase.aic"><code>StatsBase.aic</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">aic(obj::StatisticalModel)</code></pre><p>Akaike&#39;s Information Criterion, defined as <span>$-2 \log L + 2k$</span>, with <span>$L$</span> the likelihood of the model, and <code>k</code> its number of consumed degrees of freedom (as returned by <a href="constructors.html#StatsBase.dof-Tuple{StatsBase.StatisticalModel}"><code>dof</code></a>).</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L99-L105">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.bic" href="#StatsBase.bic"><code>StatsBase.bic</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">bic(obj::StatisticalModel)</code></pre><p>Bayesian Information Criterion, defined as <span>$-2 \log L + k \log n$</span>, with <span>$L$</span> the likelihood of the model,  <span>$k$</span> its number of consumed degrees of freedom (as returned by <a href="constructors.html#StatsBase.dof-Tuple{StatsBase.StatisticalModel}"><code>dof</code></a>), and <span>$n$</span> the number of observations (as returned by <a href="constructors.html#StatsBase.nobs-Tuple{StatsBase.StatisticalModel}"><code>nobs</code></a>).</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L122-L129">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.dof-Tuple{StatsBase.StatisticalModel}" href="#StatsBase.dof-Tuple{StatsBase.StatisticalModel}"><code>StatsBase.dof</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">dof(obj::StatisticalModel)</code></pre><p>Return the number of degrees of freedom consumed in the model, including when applicable the intercept and the distribution&#39;s dispersion parameter.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L67-L72">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.nobs-Tuple{StatsBase.StatisticalModel}" href="#StatsBase.nobs-Tuple{StatsBase.StatisticalModel}"><code>StatsBase.nobs</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">nobs(obj::StatisticalModel)</code></pre><p>Return the number of independent observations on which the model was fitted. Be careful when using this information, as the definition of an independent observation may vary depending on the model, on the format used to pass the data, on the sampling plan (if specified), etc.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L57-L64">source</a></section><pre><code class="language-julia">julia&gt; loglikelihood(fm1)
-163.6635299405682

julia&gt; aic(fm1)
333.3270598811364

julia&gt; bic(fm1)
337.5306520261229

julia&gt; loglikelihood(gm1)
-4067.916428181088
</code></pre><p>The <code>deviance</code> generic is documented as returning negative twice the log-likelihood adjusting for the saturated model.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.deviance-Tuple{StatsBase.StatisticalModel}" href="#StatsBase.deviance-Tuple{StatsBase.StatisticalModel}"><code>StatsBase.deviance</code></a> — <span class="docstring-category">Method</span>.</div><div><pre><code class="language-none">deviance(obj::StatisticalModel)</code></pre><p>Return the deviance of the model relative to a reference, which is usually when applicable the saturated model. It is equal, <em>up to a constant</em>, to <span>$-2 \log L$</span>, with <span>$L$</span> the likelihood of the model.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L26-L32">source</a></section><p>Because it is not clear what the saturated model corresponding to a particular <code>LinearMixedModel</code> should be, negative twice the log-likelihood is called the <code>objective</code>.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.objective" href="#MixedModels.objective"><code>MixedModels.objective</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">objective(m::LinearMixedModel)</code></pre><p>Return negative twice the log-likelihood of model <code>m</code></p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/pls.jl#L235-L239">source</a></section><p>This value is also accessible as the <code>deviance</code> but the user should bear in mind that this doesn&#39;t have all the properties of a deviance which is corrected for the saturated model. For example, it is not necessarily non-negative.</p><pre><code class="language-julia">julia&gt; objective(fm1)
327.3270598811364

julia&gt; deviance(fm1)
327.3270598811364
</code></pre><p>The value optimized when fitting a <code>GeneralizedLinearMixedModel</code> is the Laplace approximation to the deviance.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.LaplaceDeviance" href="#MixedModels.LaplaceDeviance"><code>MixedModels.LaplaceDeviance</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">LaplaceDeviance(m::GeneralizedLinearMixedModel{T})::T where T</code></pre><p>Return the Laplace approximation to the deviance of <code>m</code>.</p><p>If the distribution <code>D</code> does not have a scale parameter the Laplace approximation is defined as the squared length of the conditional modes, <code>u</code>, plus the determinant of <code>Λ&#39;Z&#39;WZΛ + I</code>, plus the sum of the squared deviance residuals.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/PIRLS.jl#L37-L45">source</a></section><pre><code class="language-julia">julia&gt; LaplaceDeviance(gm1)
8135.832856362156
</code></pre><h2><a class="nav-anchor" id="Fixed-effects-parameter-estimates-1" href="#Fixed-effects-parameter-estimates-1">Fixed-effects parameter estimates</a></h2><p>The <code>coef</code> and <code>fixef</code> extractors both return the maximum likelihood estimates of the fixed-effects coefficients.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.coef" href="#StatsBase.coef"><code>StatsBase.coef</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">coef(obj::StatisticalModel)</code></pre><p>Return the coefficients of the model.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L5-L9">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.fixef" href="#MixedModels.fixef"><code>MixedModels.fixef</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">fixef(m::MixedModel)</code></pre><p>Returns the fixed-effects parameter vector estimate.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/pls.jl#L255-L259">source</a></section><pre><code class="language-julia">julia&gt; show(coef(fm1))
[1527.5]
julia&gt; show(fixef(fm1))
[1527.5]
julia&gt; show(fixef(gm1))
[0.553446, 0.0574199, 0.320748, -1.0598, -2.10382, -1.05437, -0.706998]</code></pre><p>The variance-covariance matrix of the fixed-effects coefficients is returned by</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.vcov" href="#StatsBase.vcov"><code>StatsBase.vcov</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">vcov(obj::StatisticalModel)</code></pre><p>Return the variance-covariance matrix for the coefficients of the model.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L82-L86">source</a></section><pre><code class="language-julia">julia&gt; vcov(fm2)
2×2 Array{Float64,2}:
 43.9868   -1.37039
 -1.37039   2.25671

julia&gt; vcov(gm1)
7×7 Array{Float64,2}:
  0.148508    -0.0056049    -0.00977128   -0.0169693    -0.0171417    -0.0114539    -0.0114551  
 -0.0056049    0.000280668   7.19153e-5   -1.43716e-5   -2.90569e-5   -1.47973e-5   -1.02416e-5 
 -0.00977128   7.19153e-5    0.0365618    -9.25614e-5   -0.000162389  -8.04419e-5   -5.25875e-5 
 -0.0169693   -1.43716e-5   -9.25614e-5    0.0339111     0.0171821     0.000265802   0.000172098
 -0.0171417   -2.90569e-5   -0.000162389   0.0171821     0.0347854     0.000658966   0.000520523
 -0.0114539   -1.47973e-5   -8.04419e-5    0.000265802   0.000658966   0.0228575     0.000247782
 -0.0114551   -1.02416e-5   -5.25875e-5    0.000172098   0.000520523   0.000247782   0.022801   
</code></pre><p>The standard errors are the square roots of the diagonal elements of the estimated variance-covariance matrix of the coefficients.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.stderr" href="#StatsBase.stderr"><code>StatsBase.stderr</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">stderr(obj::StatisticalModel)</code></pre><p>Return the standard errors for the coefficients of the model.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L75-L79">source</a></section><pre><code class="language-julia">julia&gt; stderr(fm2)
2-element Array{Float64,1}:
 6.63226
 1.50224

julia&gt; stderr(gm1)
7-element Array{Float64,1}:
 0.385367 
 0.0167532
 0.191212 
 0.18415  
 0.186509 
 0.151187 
 0.151    
</code></pre><p>Finally, the <code>coeftable</code> generic produces a table of coefficient estimates, their standard errors, and their ratio. The <em>p-values</em> quoted here should be regarded as approximations.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="StatsBase.coeftable" href="#StatsBase.coeftable"><code>StatsBase.coeftable</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">coeftable(obj::StatisticalModel)</code></pre><p>Return a table of class <code>CoefTable</code> with coefficients and related statistics.</p></div><a class="source-link" target="_blank" href="https://github.com/JuliaStats/StatsBase.jl/blob/9d851b704cc135ee4ca9bf68f9b0541d64d5814f/src/statmodels.jl#L12-L16">source</a></section><pre><code class="language-julia">julia&gt; coeftable(fm2)
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)   251.405   6.63226 37.9064  &lt;1e-99
U             10.4673   1.50224 6.96781  &lt;1e-11

</code></pre><h2><a class="nav-anchor" id="Covariance-parameter-estimates-1" href="#Covariance-parameter-estimates-1">Covariance parameter estimates</a></h2><p>The covariance parameters estimates, in the form shown in the model summary, are a <code>VarCorr</code> object</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.VarCorr" href="#MixedModels.VarCorr"><code>MixedModels.VarCorr</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">VarCorr</code></pre><p>An encapsulation of information on the fitted random-effects variance-covariance matrices.</p><p><strong>Members</strong></p><ul><li><p><code>σ</code>: a <code>Vector{Vector{T}}</code> of unscaled standard deviations</p></li><li><p><code>ρ</code>: a <code>Vector{Matrix{T}}</code> of correlation matrices</p></li><li><p><code>fnms</code>: a <code>Vector{Symbol}</code> of grouping factor names</p></li><li><p><code>cnms</code>: a <code>Vector{Vector{String}}</code> of column names</p></li><li><p><code>s</code>: the estimate of σ, the standard deviation of the per-observation noise.  When there</p></li></ul><p>is no scaling factor this value is <code>NaN</code></p><p>The main purpose of defining this type is to isolate the logic in the show method.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/types.jl#L207-L222">source</a></section><pre><code class="language-julia">julia&gt; VarCorr(fm2)
Variance components:
              Column    Variance  Std.Dev.   Corr.
 G        (Intercept)  565.51067 23.780468
          U             32.68212  5.716828  0.08
 Residual              654.94145 25.591824


julia&gt; VarCorr(gm1)
Variance components:
          Column    Variance   Std.Dev.  
 id   (Intercept)  1.79357917 1.33924575
 item (Intercept)  0.11713603 0.34225142

</code></pre><p>Individual components are returned by other extractors</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.varest" href="#MixedModels.varest"><code>MixedModels.varest</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">varest(m::LinearMixedModel)</code></pre><p>Returns the estimate of σ², the variance of the conditional distribution of Y given B.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/pls.jl#L312-L316">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.sdest" href="#MixedModels.sdest"><code>MixedModels.sdest</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">sdest(m::LinearMixedModel)</code></pre><p>Return the estimate of σ, the standard deviation of the per-observation noise.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/pls.jl#L276-L280">source</a></section><pre><code class="language-julia">julia&gt; varest(fm2)
654.9414513584776

julia&gt; sdest(fm2)
25.591823916213507
</code></pre><h2><a class="nav-anchor" id="Conditional-modes-of-the-random-effects-1" href="#Conditional-modes-of-the-random-effects-1">Conditional modes of the random effects</a></h2><p>The <code>ranef</code> extractor</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.ranef" href="#MixedModels.ranef"><code>MixedModels.ranef</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">ranef(m::MixedModel; uscale=false, named=true)</code></pre><p>Return, as a <code>Vector{Vector{T}}</code> (<code>Vector{NamedVector{T}}</code> if <code>named=true</code>) the conditional modes of the random effects in model <code>m</code>.</p><p>If <code>uscale</code> is <code>true</code> the random effects are on the spherical (i.e. <code>u</code>) scale, otherwise on the original scale.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/mixedmodel.jl#L140-L147">source</a></section><pre><code class="language-julia">julia&gt; ranef(fm1)
1-element Array{Array{Float64,2},1}:
 [-16.6282 0.369516 26.9747 -21.8014 53.5798 -42.4943]

julia&gt; ranef(fm1, named=true)[1]
1×6 Named Array{Float64,2}
      A ╲ B │        A         B         C         D         E         F
────────────┼───────────────────────────────────────────────────────────
(Intercept) │ -16.6282  0.369516   26.9747  -21.8014   53.5798  -42.4943
</code></pre><p>returns the <em>conditional modes</em> of the random effects given the observed data. That is, these are the values that maximize the conditional density of the random effects given the observed data. For a <code>LinearMixedModel</code> these are also the conditional mean values.</p><p>These are sometimes called the <em>best linear unbiased predictors</em> or <a href="https://en.wikipedia.org/wiki/Best_linear_unbiased_prediction"><code>BLUPs</code></a> but that name is not particularly meaningful.</p><p>At a superficial level these can be considered as the &quot;estimates&quot; of the random effects, with a bit of hand waving, but pursuing this analogy too far usually results in confusion.</p><p>The corresponding conditional variances are returned by</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.condVar" href="#MixedModels.condVar"><code>MixedModels.condVar</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">condVar(m::MixedModel)</code></pre><p>Return the conditional variances matrices of the random effects.</p><p>The random effects are returned by <code>ranef</code> as a vector of length <code>k</code>, where <code>k</code> is the number of random effects terms.  The <code>i</code>th element is a matrix of size <code>vᵢ × ℓᵢ</code>  where <code>vᵢ</code> is the size of the vector-valued random effects for each of the <code>ℓᵢ</code> levels of the grouping factor.  Technically those values are the modes of the conditional distribution of the random effects given the observed data.</p><p>This function returns an array of <code>k</code> three dimensional arrays, where the <code>i</code>th array is of size <code>vᵢ × vᵢ × ℓᵢ</code>.  These are the diagonal blocks from the conditional variance-covariance matrix,</p><pre><code class="language-none">s² Λ(Λ&#39;Z&#39;ZΛ + I)⁻¹Λ&#39;</code></pre></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/mixedmodel.jl#L170-L187">source</a></section><pre><code class="language-julia">julia&gt; condVar(fm1)
1-element Array{Array{Float64,3},1}:
 [362.31]

[362.31]

[362.31]

[362.31]

[362.31]

[362.31]
</code></pre><h1><a class="nav-anchor" id="Optimization-of-the-objective-1" href="#Optimization-of-the-objective-1">Optimization of the objective</a></h1><p>To determine the maximum likelihood estimates (mle&#39;s) of the parameters in a <code>LinearMixedModel</code> the <code>objective</code>, negative twice the log-likelihood, is minimized.   This objective is on the scale of the <a href="https://en.wikipedia.org/wiki/Deviance_(statistics)"><em>deviance</em></a>.</p><p>would involve a nonlinear optimization over all the parameters but the optimization can be simplified by evaluating the profiled log-likelihood.  </p><p>In practice it is more common to minimize negative twice the log-likelihood which is the <code>objective</code> for a <code>LinearMixedModel</code>.</p><p>By definition the objective is a function of all the parameters in the model. However, it is possible to evaluate a <em>profiled log-likelihood</em>, which is a function of only the parameters θ that determine the <em>relative covariance factor</em>. That is, given a value of θ, it is possible through a direct (i.e. non-iterative) calculation to determine the estimates of β, the fixed-effects coefficients, and σ, the standard deviation of the per-observation noise term.</p><h1><a class="nav-anchor" id="Internal-representation-1" href="#Internal-representation-1">Internal representation</a></h1><p>A <code>LinearMixedModel</code> is composed of a vector of terms and some blocked arrays associated with them.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.LinearMixedModel" href="#MixedModels.LinearMixedModel"><code>MixedModels.LinearMixedModel</code></a> — <span class="docstring-category">Type</span>.</div><div><pre><code class="language-none">LinearMixedModel</code></pre><p>Linear mixed-effects model representation</p><p><strong>Members</strong></p><ul><li><p><code>formula</code>: the formula for the model</p></li><li><p><code>trms</code>: a <code>Vector{AbstractTerm}</code> representing the model.  The last element is the response.</p></li><li><p><code>sqrtwts</code>: vector of square roots of the case weights.  Can be empty.</p></li><li><p><code>A</code>: an <code>nt × nt</code> symmetric <code>BlockMatrix</code> of matrices representing <code>hcat(Z,X,y)&#39;hcat(Z,X,y)</code></p></li><li><p><code>L</code>: a <code>nt × nt</code> <code>BlockMatrix</code> - the lower Cholesky factor of <code>Λ&#39;AΛ+I</code></p></li><li><p><code>optsum</code>: an <a href="optimization.html#MixedModels.OptSummary"><code>OptSummary</code></a> object</p></li></ul></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/types.jl#L155-L167">source</a></section><p>Other extractors are defined in the <code>MixedModels</code> package itself.</p><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.fnames" href="#MixedModels.fnames"><code>MixedModels.fnames</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">fnames(m::MixedModel)</code></pre><p>Return the names of the grouping factors for the random-effects terms.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/mixedmodel.jl#L61-L65">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.getΛ" href="#MixedModels.getΛ"><code>MixedModels.getΛ</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">getΛ(m::MixedModel)</code></pre><p>Return a vector of covariance template matrices for the random effects of <code>m</code></p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/mixedmodel.jl#L80-L84">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.getθ" href="#MixedModels.getθ"><code>MixedModels.getθ</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">getθ(A::AbstractFactorReTerm)</code></pre><p>Return a vector of the elements of the lower triangle blocks in <code>A.Λ</code> (column-major ordering)</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/modelterms.jl#L290-L294">source</a><div><pre><code class="language-none">getθ(m::MixedModel)</code></pre><p>Return the current covariance parameter vector.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/mixedmodel.jl#L87-L91">source</a></section><section class="docstring"><div class="docstring-header"><a class="docstring-binding" id="MixedModels.lowerbd" href="#MixedModels.lowerbd"><code>MixedModels.lowerbd</code></a> — <span class="docstring-category">Function</span>.</div><div><pre><code class="language-none">lowerbd{T}(A::FactorReTerm{T})
lowerbd{T}(A::MatrixTerm{T})
lowerbd{T}(v::Vector{AbstractTerm{T}})</code></pre><p>Return the vector of lower bounds on the parameters, <code>θ</code>.</p><p>These are the elements in the lower triangle in column-major ordering. Diagonals have a lower bound of <code>0</code>.  Off-diagonals have a lower-bound of <code>-Inf</code>.</p></div><a class="source-link" target="_blank" href="https://github.com/dmbates/MixedModels.jl/blob/de0bb77de0ab7693e2233df25530e3b167943096/src/modelterms.jl#L302-L311">source</a></section><p>Applied to one of the models previously fit these yield</p><pre><code class="language-julia">julia&gt; fixef(fm1)
1-element Array{Float64,1}:
 1527.5

julia&gt; coef(fm1)
1-element Array{Float64,1}:
 1527.5

julia&gt; coeftable(fm1)
             Estimate Std.Error z value P(&gt;|z|)
(Intercept)    1527.5   17.6946  86.326  &lt;1e-99


julia&gt; getΛ(fm1)
1-element Array{Float64,1}:
 0.752581

julia&gt; getθ(fm1)
1-element Array{Float64,1}:
 0.752581

julia&gt; loglikelihood(fm1)
-163.6635299405682

julia&gt; pwrss(fm1)
73537.50101605429

julia&gt; showall(ranef(fm1))
Array{Float64,2}[[-16.6282 0.369516 26.9747 -21.8014 53.5798 -42.4943]]
julia&gt; showall(ranef(fm1, uscale=true))
Array{Float64,2}[[-22.0949 0.490999 35.8429 -28.9689 71.1948 -56.4648]]
julia&gt; sdest(fm1)
49.51010032173714

julia&gt; std(fm1)
2-element Array{Array{Float64,1},1}:
 [37.2603]
 [49.5101]

julia&gt; stderr(fm1)
1-element Array{Float64,1}:
 17.6946

julia&gt; varest(fm1)
2451.2500338684763

julia&gt; vcov(fm1)
1×1 Array{Float64,2}:
 313.097
</code></pre><footer><hr/><a class="previous" href="index.html"><span class="direction">Previous</span><span class="title">MixedModels.jl Documentation</span></a><a class="next" href="optimization.html"><span class="direction">Next</span><span class="title">Details of the parameter estimation</span></a></footer></article></body></html>
